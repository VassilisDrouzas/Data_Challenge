{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["KuOdrD3j5gJ6","t2CwGqX9ZeZO","X1J94PR_gqX-","7BSPDLSYhGnS"],"authorship_tag":"ABX9TyOCPb+w9YbeQZUs3jiMWvj0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ZWyTijhrkC5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715339302954,"user_tz":-180,"elapsed":2466,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"47b9698d-262d-432c-a293-9d297afc7517"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import csv\n","import networkx as nx\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import zipfile\n","import re\n","import pandas as pd\n","import re\n","import nltk\n","import transformers\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import unicodedata as ud\n","# import optuna\n","\n","import csv\n","import networkx as nx\n","import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import cross_val_score, KFold\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, fowlkes_mallows_score\n","from sklearn.decomposition import PCA\n","from io import BytesIO\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from transformers import AutoTokenizer,TFAutoModel\n","from nltk.tokenize import word_tokenize\n","from random import choice\n","from gensim.models import Word2Vec"],"metadata":{"id":"rWXMWYF5kCwr","executionInfo":{"status":"ok","timestamp":1715339302954,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f1d0b4c1-d17a-4baf-d0b7-b26059955cbf"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","execution_count":67,"metadata":{"id":"S-NSfTkfj9sv","executionInfo":{"status":"ok","timestamp":1715341266405,"user_tz":-180,"elapsed":56822,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5100743-8f5c-4728-8841-6a9a0f892c22"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of nodes: 65208\n","Number of edges: 1642073\n"]}],"source":["# file_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"data_challenge\", \"train.txt\")\n","# read training data\n","train_domains = list()\n","y_train = list()\n","with open(\"/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Data_challenge/project/data/train.txt\", 'r') as f:\n","# with open(\"../../../../../data_challenge/train.txt\", 'r') as f:\n","    for line in f:\n","        l = line.split(',') # domain names\n","        train_domains.append(l[0])\n","        y_train.append(l[1][:-1]) # topics of domain names\n","\n","# read test data\n","test_domains = list()\n","with open(\"/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Data_challenge/project/data/test.txt\", 'r') as f:\n","# with open(\"../../../../../data_challenge/test.txt\", 'r') as f:\n","    for line in f:\n","        l = line.split(',')\n","        test_domains.append(l[0])\n","\n","# create a directed graph\n","G = nx.read_edgelist('/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Data_challenge/project/data/edgelist.txt', delimiter=' ',\n","#                       create_using=nx.DiGraph())\n","\n","# G = nx.read_edgelist('../../../../../data_challenge/edgelist.txt', delimiter=' ',\n","                      create_using=nx.DiGraph())\n","\n","print('Number of nodes:', G.number_of_nodes())\n","print('Number of edges:', G.number_of_edges())\n","\n","\n","# read textual content of webpages of domain names\n","text = dict()\n","with zipfile.ZipFile('/content/drive/Othercomputers/My Computer/Masters_Staff/trimester_3/Data_challenge/project/data/domains.zip', \"r\") as zfile:\n","\n","# with zipfile.ZipFile('../../../../../data_challenge/domains.zip', \"r\") as zfile:\n","    for filename in zfile.namelist():\n","        if re.search(r'\\.zip$', filename) is not None:\n","            zfiledata = BytesIO(zfile.read(filename))\n","            with zipfile.ZipFile(zfiledata) as zfile2:\n","                text[filename[:-4]] = ''\n","                for name2 in zfile2.namelist():\n","                    file = zfile2.read(name2)\n","                    text[filename[:-4]] += file.decode('utf16') + ' '\n","\n","# retrieve textual content of domain names of the training set\n","train_data = list()\n","for domain in train_domains:\n","    if domain in text:\n","        train_data.append(text[domain])\n","    else:\n","        train_data.append('')\n","\n","\n","# retrieve textual content of domain names of the test set\n","test_data = list()\n","for domain in test_domains:\n","    if domain in text:\n","        test_data.append(text[domain])\n","    else:\n","        test_data.append('')\n","\n","# to reduce memory\n","text = None"]},{"cell_type":"markdown","source":["### Create validation set"],"metadata":{"id":"gdLgftC0M5PD"}},{"cell_type":"code","source":["train_df = pd.DataFrame({'domain':train_domains, 'y':y_train})\n"],"metadata":{"id":"PcnW29X7SLV2","executionInfo":{"status":"ok","timestamp":1715341266405,"user_tz":-180,"elapsed":4,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_dev, y_train, y_dev = train_test_split(train_df['domain'], train_df['y'], test_size=0.20, random_state=4321)\n","\n","print(X_train.shape, X_dev.shape, y_train.shape, y_dev.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpQYaGzlM9cw","executionInfo":{"status":"ok","timestamp":1715341266406,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"3c0d57ae-6ee8-4ded-cb49-d6277f540b46"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["(1449,) (363,) (1449,) (363,)\n"]}]},{"cell_type":"markdown","source":["### Create long tensor for GraphSage"],"metadata":{"id":"FHnZxHNwhMEA"}},{"cell_type":"code","source":["# Initialize a boolean tensor with False for all nodes\n","train_nodes_tensor = torch.zeros(G.number_of_nodes(), dtype=torch.bool)\n","\n","# Iterate over the nodes in the graph\n","for idx, node in enumerate(G.nodes()):\n","    # Check if the node is in train_domains\n","    if node in X_train:\n","        train_nodes_tensor[idx] = True\n","\n","print(train_nodes_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cygI4KVgfRBx","executionInfo":{"status":"ok","timestamp":1715344323580,"user_tz":-180,"elapsed":258,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"2a783e2f-81ba-4199-da8e-59e8b801a6af"},"execution_count":122,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([False, False, False,  ..., False, False, False])\n"]}]},{"cell_type":"markdown","source":["### Community"],"metadata":{"id":"KuOdrD3j5gJ6"}},{"cell_type":"code","source":["# coding=utf-8\n","\n","\n","class Status(object):\n","    \"\"\"\n","    To handle several data in one struct.\n","\n","    Could be replaced by named tuple, but don't want to depend on python 2.6\n","    \"\"\"\n","    node2com = {}\n","    total_weight = 0\n","    internals = {}\n","    degrees = {}\n","    gdegrees = {}\n","\n","    def __init__(self):\n","        self.node2com = dict([])\n","        self.total_weight = 0\n","        self.degrees = dict([])\n","        self.gdegrees = dict([])\n","        self.internals = dict([])\n","        self.loops = dict([])\n","\n","    def __str__(self):\n","        return (\"node2com : \" + str(self.node2com) + \" degrees : \"\n","                + str(self.degrees) + \" internals : \" + str(self.internals)\n","                + \" total_weight : \" + str(self.total_weight))\n","\n","    def copy(self):\n","        \"\"\"Perform a deep copy of status\"\"\"\n","        new_status = Status()\n","        new_status.node2com = self.node2com.copy()\n","        new_status.internals = self.internals.copy()\n","        new_status.degrees = self.degrees.copy()\n","        new_status.gdegrees = self.gdegrees.copy()\n","        new_status.total_weight = self.total_weight\n","\n","    def init(self, graph, weight, part=None):\n","        \"\"\"Initialize the status of a graph with every node in one community\"\"\"\n","        count = 0\n","        self.node2com = dict([])\n","        self.total_weight = 0\n","        self.degrees = dict([])\n","        self.gdegrees = dict([])\n","        self.internals = dict([])\n","        self.total_weight = graph.size(weight=weight)\n","        if part is None:\n","            for node in graph.nodes():\n","                self.node2com[node] = count\n","                deg = float(graph.degree(node, weight=weight))\n","                if deg < 0:\n","                    error = \"Bad node degree ({})\".format(deg)\n","                    raise ValueError(error)\n","                self.degrees[count] = deg\n","                self.gdegrees[node] = deg\n","                edge_data = graph.get_edge_data(node, node, default={weight: 0})\n","                self.loops[node] = float(edge_data.get(weight, 1))\n","                self.internals[count] = self.loops[node]\n","                count += 1\n","        else:\n","            for node in graph.nodes():\n","                com = part[node]\n","                self.node2com[node] = com\n","                deg = float(graph.degree(node, weight=weight))\n","                self.degrees[com] = self.degrees.get(com, 0) + deg\n","                self.gdegrees[node] = deg\n","                inc = 0.\n","                for neighbor, datas in graph[node].items():\n","                    edge_weight = datas.get(weight, 1)\n","                    if edge_weight <= 0:\n","                        error = \"Bad graph type ({})\".format(type(graph))\n","                        raise ValueError(error)\n","                    if part[neighbor] == com:\n","                        if neighbor == node:\n","                            inc += float(edge_weight)\n","                        else:\n","                            inc += float(edge_weight) / 2.\n","                self.internals[com] = self.internals.get(com, 0) + inc\n","\n","# class usage\n","status = Status()\n","status.init(G,1642073)\n","# status.node2com"],"metadata":{"id":"OCyvYfXBVqRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["status.internals"],"metadata":{"id":"LsqyoECIqj-F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Find-out community number\n","def cluster_keys_by_value(input_dict):\n","    clusters = {}\n","\n","    # reverse the input dictionary to create a new dictionary where values become keys\n","    reversed_dict = {}\n","    for key, value in input_dict.items():\n","        reversed_dict.setdefault(value, []).append(key)\n","\n","    # iterate over unique values in the reversed dictionary\n","    for value, keys in reversed_dict.items():\n","        # add keys associated with the same value to the cluster\n","        clusters[value] = keys\n","\n","    # filter and sort to find communities\n","    filtered_clusters = {value: keys for value, keys in clusters.items() if len(keys)>1}\n","    sorted_clusters = sorted_comms = sorted(filtered_clusters.items(),\n","                                            key=lambda kv: len(kv[1]), reverse=True)\n","    return sorted_clusters"],"metadata":{"id":"e7q_LAWbi8Qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["status = Status() # class object\n","\n","# check a range of values for weight\n","for weight in range(-1000, 1000):\n","\n","  status.init(G, weight)\n","  sorted_comms = cluster_keys_by_value(status.node2com)\n","\n","  if sorted_comms:\n","    print(f\"Communities can be build with weight: {weight}\")\n","    break"],"metadata":{"id":"usIQ1XMXjFWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(y_train),len(train_domains)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SIge6KYq9tix","executionInfo":{"status":"ok","timestamp":1715154420186,"user_tz":-180,"elapsed":9,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"024a6735-fe64-4502-d984-496704d43495"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1812, 1812)"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["## here subgraph will be the developement set\n","\n","# create a subgraph\n","num_nodes_sub = int(0.01 * len(G))\n","sub_nodes = list(G.nodes())[:num_nodes_sub] # subset of nodes\n","subg = G.subgraph(sub_nodes)\n","\n","# retrieve domains && labels\n","subg_domains = [domain for domain in train_domains if domain in subg.nodes()]\n","ydev_sub = [y_train[train_domains.index(node)] for node in subg.nodes() if node in train_domains]\n","\n","# re-create the big part of the net\n","new_G = G.copy()\n","new_G.remove_nodes_from(subg.nodes())\n","new_train_dom = [domain for domain in train_domains if domain not in subg_domains]\n","ytr = [y_train[train_domains.index(node)] for node in new_G.nodes() if node in train_domains]"],"metadata":{"id":"R-NtEWm6kE7Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(ydev_sub),subg.number_of_nodes(), len(subg_domains)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"no7D-o1b8hIz","executionInfo":{"status":"ok","timestamp":1715157213314,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"814c065a-082f-4763-edda-d4335b8f966e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(147, 652, 147)"]},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":[],"metadata":{"id":"MtpebbrGmsAz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DEEPWALK"],"metadata":{"id":"ySGEXn-l7AX6"}},{"cell_type":"code","source":["def random_walk(G, node, walk_length):\n","    # Starts from vertex \"node\" and performs a random walk of length \"walk length\". Returns a list of the visited vertices\n","    walk = [node]\n","\n","    for _ in range(walk_length-1):\n","        neighbors = list(G.neighbors(walk[-1]))\n","        if len(neighbors) > 0:\n","            neighbor = choice(neighbors)\n","            walk.append(neighbor)\n","        else:\n","            break\n","\n","    walk = [str(node) for node in walk]\n","    return walk\n","\n","\n","def generate_walks(G, num_walks, walk_length):\n","    # Runs \"num_walks\" random walks from each node, and returns a list of all random walk\n","    walks = []\n","\n","    for _ in range(num_walks):\n","        for node in G.nodes():\n","            walk = random_walk(G, node, walk_length)\n","            walks.append(walk)\n","\n","    return walks\n","\n","\n","graph_walks = generate_walks(G, 10, 40)\n","\n","# initialize word2vec object\n","model = Word2Vec(graph_walks, vector_size=128, window=10, min_count=0, sg=1, workers=8, epochs=5)\n","\n","\n","# function to generate node embeddings based on deepwalk and w2v\n","def deepwalk_to_vector(data_domains,w2v_model,dims=128):\n","\n","  #  Each row corresponds to a web host.\n","  embs = np.zeros((len(data_domains), dims)) # create the training matrix.\n","  for i, domain in enumerate(data_domains):\n","      embs[i,:] = model.wv[domain]\n","\n","  return embs\n","\n","# generate embeddings\n","Xtr_emb = deepwalk_to_vector(X_train,model)\n","Xde_emb = deepwalk_to_vector(X_dev,model)\n","Xte_emb = deepwalk_to_vector(test_domains,model)\n"],"metadata":{"id":"cJk28pwD67uv","executionInfo":{"status":"ok","timestamp":1715342250792,"user_tz":-180,"elapsed":55488,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["def multiclass_cross_entropy(y_true, y_pred_prob):\n","    epsilon = 1e-15  # small value to prevent log(0)\n","    # clip predicted probabilities to avoid log(0)\n","    y_pred_prob = np.clip(y_pred_prob, epsilon, 1 - epsilon)\n","    # compute cross-entropy loss\n","\n","    loss = -np.mean(np.sum(y_true * np.log(y_pred_prob), axis=1))\n","    return loss"],"metadata":{"id":"d_u2SwkBCAX9","executionInfo":{"status":"ok","timestamp":1715342250792,"user_tz":-180,"elapsed":9,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","ytrain_en = tf.keras.utils.to_categorical(y_train, num_classes=9)\n","ydev_en= tf.keras.utils.to_categorical(y_dev,num_classes=9)"],"metadata":{"id":"6lfPiLuXCt5D","executionInfo":{"status":"ok","timestamp":1715342250793,"user_tz":-180,"elapsed":9,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":95,"outputs":[]},{"cell_type":"code","source":["# use logistic regression to classify the webpages of the test set\n","clf = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1500)\n","clf.fit(Xtr_emb, y_train)\n","y_pred_tr = clf.predict_proba(Xtr_emb)\n","y_pred_de = clf.predict_proba(Xde_emb)\n","\n","\n","ce_train = multiclass_cross_entropy(ytrain_en, y_pred_tr)\n","ce_dev = multiclass_cross_entropy(ydev_en, y_pred_de)\n","\n","print(f\"Cross Entropy Loss for Train: {ce_train}\")\n","print(f\"Cross Entropy Loss for Dev: {ce_dev}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aiYyB4B7-dwH","executionInfo":{"status":"ok","timestamp":1715342250793,"user_tz":-180,"elapsed":9,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"50e5e2aa-4c4d-44ad-cd16-9e7e68d699d1"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross Entropy Loss for Train: 0.8483325005134608\n","Cross Entropy Loss for Dev: 1.1640980708234865\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install optuna"],"metadata":{"id":"vyLKezjkUMm-","executionInfo":{"status":"ok","timestamp":1715341432368,"user_tz":-180,"elapsed":7531,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["import optuna\n","def objective(trial, X, y):\n","    # define hyperparameters to optimize\n","    C = trial.suggest_float('C', 0.01, 100, log=True)\n","    penalty = trial.suggest_categorical('penalty', ['l2'])\n","    max_iter = trial.suggest_int('max_iter', 1000, 5000)\n","\n","    model = LogisticRegression(C=C, penalty=penalty, max_iter=max_iter, solver='liblinear')\n","\n","    # perform cross-validation\n","    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","    scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n","\n","    # return average accuracy as the objective value\n","    return scores.mean()\n","\n","# begin studies\n","study = optuna.create_study(direction='maximize')\n","study.optimize(lambda trial: objective(trial, Xtr_emb, y_train), n_trials=40)\n","\n","best_params = study.best_params\n","best_score = study.best_value\n","\n","print(\"Best parameters:\", best_params)\n","\n","print(\"Best score:\", best_score)\n"],"metadata":{"id":"3ce2SxbwUBim"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_lr = LogisticRegression(**best_params)\n","best_lr.fit(Xtr_emb, y_train)\n","\n","yde_b_lr = best_lr.predict_proba(Xde_emb)\n","ce_dev = multiclass_cross_entropy(ydev_en, yde_b_lr)\n","print(f\"Cross Entropy Loss for Dev: {ce_dev}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WqsWgYWEUCar","executionInfo":{"status":"ok","timestamp":1715342322392,"user_tz":-180,"elapsed":10,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"75675f07-cf81-494a-8645-3bf9fc6eac9f"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["Cross Entropy Loss for Dev: 1.1258391085185928\n"]}]},{"cell_type":"markdown","source":["### GraphSage"],"metadata":{"id":"Kb_2Mzw9X72o"}},{"cell_type":"code","source":["from torch_geometric.datasets import Planetoid\n","\n","dataset = Planetoid(root='.', name=\"Pubmed\")\n","data = dataset[0]\n","\n","print(type(dataset[0]))\n","# # Print information about the dataset\n","# print(f'Dataset: {dataset}')\n","# print('-------------------')\n","# print(f'Number of graphs: {len(dataset)}')\n","# print(f'Number of nodes: {data.x.shape[0]}')\n","# print(f'Number of features: {dataset.num_features}')\n","# print(f'Number of classes: {dataset.num_classes}')\n","\n","# # Print information about the graph\n","# print(f'\\nGraph:')\n","# print('------')\n","# print(f'Training nodes: {sum(data.train_mask).item()}')\n","# print(f'Evaluation nodes: {sum(data.val_mask).item()}')\n","# print(f'Test nodes: {sum(data.test_mask).item()}')\n","# print(f'Edges are directed: {data.is_directed()}')\n","# print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n","# print(f'Graph has loops: {data.has_self_loops()}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLSaji6MX-DV","executionInfo":{"status":"ok","timestamp":1715344395888,"user_tz":-180,"elapsed":246,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"3064f21f-3649-4fbe-ca17-80393fbb0037"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'torch_geometric.data.data.Data'>\n"]}]},{"cell_type":"code","source":["y_train = torch.tensor( np.array(y_train).astype('int64') )\n","y_dev = torch.tensor( np.array(y_dev).astype('int64') )"],"metadata":{"id":"b11mzfZ4c7GY","executionInfo":{"status":"ok","timestamp":1715345791656,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":166,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, input_nodes, labels):\n","        self.input_nodes = input_nodes\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.input_nodes)\n","\n","    def __getitem__(self, idx):\n","        return self.input_nodes[idx], self.labels[idx]\n","\n","tr_dataset = CustomDataset(train_nodes_tensor, y_train)\n","data = pyg_utils.from_networkx(G) # transform nx graph torch_geometric.data.data.Data"],"metadata":{"id":"Qj84YXqej_8u","executionInfo":{"status":"ok","timestamp":1715345826902,"user_tz":-180,"elapsed":28568,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":168,"outputs":[]},{"cell_type":"code","source":["train_nodes_tensor.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QszmZfh6lN1M","executionInfo":{"status":"ok","timestamp":1715345881396,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"bb327d6f-720b-4c2f-e63c-110628d8e93e"},"execution_count":170,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([65208])"]},"metadata":{},"execution_count":170}]},{"cell_type":"code","source":["type(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"tskUpoYakWPp","executionInfo":{"status":"ok","timestamp":1715345653678,"user_tz":-180,"elapsed":3,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"6b56b1fb-d5cc-470c-86ab-17aa279eff8e"},"execution_count":158,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch_geometric.data.data.Data"],"text/html":["<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n","      pre.function-repr-contents {\n","        overflow-x: auto;\n","        padding: 8px 12px;\n","        max-height: 500px;\n","      }\n","\n","      pre.function-repr-contents.function-repr-contents-collapsed {\n","        cursor: pointer;\n","        max-height: 100px;\n","      }\n","    </style>\n","    <pre style=\"white-space: initial; background:\n","         var(--colab-secondary-surface-color); padding: 8px 12px;\n","         border-bottom: 1px solid var(--colab-border-color);\"><b>torch_geometric.data.data.Data</b><br/>def __call__(*args: str) -&gt; Iterable</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/torch_geometric/data/data.py</a>A data object describing a homogeneous graph.\n","The data object can hold node-level, link-level and graph-level attributes.\n","In general, :class:`~torch_geometric.data.Data` tries to mimic the\n","behavior of a regular :python:`Python` dictionary.\n","In addition, it provides useful functionality for analyzing graph\n","structures, and provides basic PyTorch tensor functionalities.\n","See `here &lt;https://pytorch-geometric.readthedocs.io/en/latest/get_started/\n","introduction.html#data-handling-of-graphs&gt;`__ for the accompanying\n","tutorial.\n","\n",".. code-block:: python\n","\n","    from torch_geometric.data import Data\n","\n","    data = Data(x=x, edge_index=edge_index, ...)\n","\n","    # Add additional arguments to `data`:\n","    data.train_idx = torch.tensor([...], dtype=torch.long)\n","    data.test_mask = torch.tensor([...], dtype=torch.bool)\n","\n","    # Analyzing the graph structure:\n","    data.num_nodes\n","    &gt;&gt;&gt; 23\n","\n","    data.is_directed()\n","    &gt;&gt;&gt; False\n","\n","    # PyTorch tensor functionality:\n","    data = data.pin_memory()\n","    data = data.to(&#x27;cuda:0&#x27;, non_blocking=True)\n","\n","Args:\n","    x (torch.Tensor, optional): Node feature matrix with shape\n","        :obj:`[num_nodes, num_node_features]`. (default: :obj:`None`)\n","    edge_index (LongTensor, optional): Graph connectivity in COO format\n","        with shape :obj:`[2, num_edges]`. (default: :obj:`None`)\n","    edge_attr (torch.Tensor, optional): Edge feature matrix with shape\n","        :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n","    y (torch.Tensor, optional): Graph-level or node-level ground-truth\n","        labels with arbitrary shape. (default: :obj:`None`)\n","    pos (torch.Tensor, optional): Node position matrix with shape\n","        :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n","    time (torch.Tensor, optional): The timestamps for each event with shape\n","        :obj:`[num_edges]` or :obj:`[num_nodes]`. (default: :obj:`None`)\n","    **kwargs (optional): Additional attributes.</pre>\n","      <script>\n","      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n","        for (const element of document.querySelectorAll('.filepath')) {\n","          element.style.display = 'block'\n","          element.onclick = (event) => {\n","            event.preventDefault();\n","            event.stopPropagation();\n","            google.colab.files.view(element.textContent, 469);\n","          };\n","        }\n","      }\n","      for (const element of document.querySelectorAll('.function-repr-contents')) {\n","        element.onclick = (event) => {\n","          event.preventDefault();\n","          event.stopPropagation();\n","          element.classList.toggle('function-repr-contents-collapsed');\n","        };\n","      }\n","      </script>\n","      </div>"]},"metadata":{},"execution_count":158}]},{"cell_type":"code","source":["from torch_geometric.loader import NeighborLoader\n","from torch_geometric.utils import to_networkx\n","import torch_geometric.utils as pyg_utils\n","\n","\n","\n","# Create batches with neighbor sampling\n","train_loader = NeighborLoader(\n","    data,\n","    num_neighbors=[5, 10],\n","    batch_size=16,\n","    input_nodes=tr_dataset,\n",")\n","\n","# Print each subgraph\n","for i, subgraph in enumerate(train_loader):\n","    print(f'Subgraph {i}: {subgraph}')\n","\n","# Plot each subgraph\n","fig = plt.figure(figsize=(16,16))\n","for idx, (subdata, pos) in enumerate(zip(train_loader, [221, 222, 223, 224])):\n","    G = to_networkx(subdata, to_undirected=True)\n","    ax = fig.add_subplot(pos)\n","    ax.set_title(f'Subgraph {idx}')\n","    plt.axis('off')\n","    nx.draw_networkx(G,\n","                    pos=nx.spring_layout(G, seed=0),\n","                    with_labels=True,\n","                    node_size=200,\n","                    node_color=subdata.y,\n","                    cmap=\"cool\",\n","                    font_size=10\n","                    )\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"0kehQ0MmYzI4","executionInfo":{"status":"error","timestamp":1715345827272,"user_tz":-180,"elapsed":379,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"cac89dc4-374b-4201-be47-4cc49b157488"},"execution_count":169,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n","  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"]},{"output_type":"error","ename":"ValueError","evalue":"expected sequence of length 65208 at dim 0 (got 1449)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-169-bcbc858d37ff>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create batches with neighbor sampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m train_loader = NeighborLoader(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnum_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/neighbor_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, num_neighbors, input_nodes, input_time, replace, subgraph_type, disjoint, temporal_strategy, time_attr, weight_attr, transform, transform_sampler_output, is_sorted, filter_per_worker, neighbor_sampler, directed, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m             )\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mnode_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneighbor_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/node_loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, node_sampler, input_nodes, input_time, transform, transform_sampler_output, filter_per_worker, custom_cls, input_id, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Get node type (or `None` for homogeneous graphs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         input_type, input_nodes, input_id = get_input_nodes(\n\u001b[0m\u001b[1;32m    121\u001b[0m             data, input_nodes, input_id)\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mget_input_nodes\u001b[0;34m(data, input_nodes, input_id)\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_nodes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mto_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/loader/utils.py\u001b[0m in \u001b[0;36mto_index\u001b[0;34m(nodes, input_id)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mnodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: expected sequence of length 65208 at dim 0 (got 1449)"]}]},{"cell_type":"code","source":["for batch in train_loader:\n","  print(batch.y)\n"],"metadata":{"id":"0PrXocEUjRKM","executionInfo":{"status":"ok","timestamp":1715345399790,"user_tz":-180,"elapsed":240,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":153,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch_geometric.nn import SAGEConv\n","import torch.nn.functional as F\n","from torch_geometric.data import DataLoader\n","from torch_geometric.datasets import Planetoid\n","\n","class GraphSAGE(torch.nn.Module):\n","  \"\"\"GraphSAGE\"\"\"\n","  def __init__(self, dim_in, dim_h, dim_out):\n","    super().__init__()\n","    self.sage1 = SAGEConv(dim_in, dim_h)\n","    self.sage2 = SAGEConv(dim_h, dim_out)\n","    self.optimizer = torch.optim.Adam(self.parameters(),\n","                                      lr=0.01,\n","                                      weight_decay=5e-4)\n","\n","  def forward(self, x, edge_index):\n","    h = self.sage1(x, edge_index)\n","    h = torch.relu(h)\n","    h = F.dropout(h, p=0.5, training=self.training)\n","    h = self.sage2(h, edge_index)\n","    return h, F.log_softmax(h, dim=1)\n","\n","  def fit(self, train_loader, epochs):\n","    criterion = torch.nn.CrossEntropyLoss()\n","    optimizer = self.optimizer\n","\n","    self.train()\n","    for epoch in range(epochs+1):\n","        acc = 0\n","        val_loss = 0\n","        val_acc = 0\n","\n","        # Train on batches\n","        for batch in train_loader:\n","            optimizer.zero_grad()\n","            _, out = self(batch.x, batch.edge_index)\n","            loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n","            acc += accuracy(out[batch.train_mask].argmax(dim=1), batch.y[batch.train_mask])\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Validation\n","            val_loss += criterion(out[batch.val_mask], batch.y[batch.val_mask])\n","            val_acc += accuracy(out[batch.val_mask].argmax(dim=1), batch.y[batch.val_mask])\n","\n","        # # Print metrics every 10 epochs\n","        # if(epoch % 10 == 0):\n","        #     print(f'Epoch {epoch:>3} | Train Loss: {loss/len(train_loader):.3f} '\n","        #           f'| Train Acc: {acc/len(train_loader)*100:>6.2f}% | Val Loss: '\n","        #           f'{val_loss/len(train_loader):.2f} | Val Acc: '\n","        #           f'{val_acc/len(train_loader)*100:.2f}%')\n","\n","\n","\n","# GraphSage instance\n","gSage = GraphSAGE(Xtr_emb.shape[1], 100, 9)\n","\n","# train graphsage\n","gSage.fit(train_loader,100)"],"metadata":{"id":"e1bvmYrxZgs0","executionInfo":{"status":"ok","timestamp":1715345140159,"user_tz":-180,"elapsed":241,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}}},"execution_count":144,"outputs":[]},{"cell_type":"code","source":["#### Get Edge Index Array\n","def edge_list(graph):\n","  edge_list = list(graph.edges)\n","  edge_index_matrix = np.array(edge_list).T\n","  return edge_index_matrix\n","\n","edge_list  = edge_list(G)\n","\n","# # re-create the big part of the net\n","# tr_G = G.copy()\n","# tr_G.remove_nodes_from(subg.nodes())\n","# new_train_dom = [domain for domain in train_domains if domain not in subg_domains]\n","# ytr = [y_train[train_domains.index(node)] for node in new_G.nodes() if node in train_domains]"],"metadata":{"id":"xydasaDManXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H_YxD96NiLyy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GCN on Graph (Pytorch Geometric)"],"metadata":{"id":"t2CwGqX9ZeZO"}},{"cell_type":"code","source":["%%capture\n","%pip install torch_geometric\n","import torch_geometric\n","import torch_geometric.nn as g_nn\n","import torch_geometric.data as g_data\n","\n","from torch_geometric.nn import GCNConv"],"metadata":{"id":"uaiJkk-kZ5ni"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_class = 9\n","\n","class GCN(torch.nn.Module):\n","  def __init__(self, hidden_channels):\n","    super().__init__()\n","    torch.manual_seed(1234567)\n","    self.conv1 = GCNConv(w2v_train.shape[1], hidden_channels)\n","    self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","    self.conv3 = GCNConv(hidden_channels, hidden_channels)\n","    self.conv4 = GCNConv(hidden_channels, num_class)\n","\n","  def forward(self, x, edge_index):\n","    x = self.conv1(x, edge_index)\n","    x = x.relu()\n","    x = F.dropout(x, p=0.3, training=self.training)\n","    x = self.conv2(x, edge_index)\n","    x = x.relu()\n","    x = F.dropout(x, p=0.3, training=self.training)\n","    x = self.conv3(x, edge_index)\n","    x = F.dropout(x, p=0.3, training=self.training)\n","    x = self.conv4(x, edge_index)\n","    return x\n","\n","model = GCN(hidden_channels=16)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WUWc6KkKZ56a","executionInfo":{"status":"ok","timestamp":1715326287163,"user_tz":-180,"elapsed":332,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"76713ee2-d829-44f8-a6a0-47afbf56967f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GCN(\n","  (conv1): GCNConv(128, 16)\n","  (conv2): GCNConv(16, 16)\n","  (conv3): GCNConv(16, 16)\n","  (conv4): GCNConv(16, 9)\n",")\n"]}]},{"cell_type":"code","source":["w2v_train = .astype('float64')"],"metadata":{"id":"XxPBeSXRbeBL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w2v_train = torch.tensor(w2v_train)"],"metadata":{"id":"7b44Zeb6bnro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w2v_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h1R_vDU0bqtI","executionInfo":{"status":"ok","timestamp":1715327203509,"user_tz":-180,"elapsed":1,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"56074a2a-becf-4523-e382-0e92768c46a7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1812, 128])"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","\n","# reshape array to single list of strs\n","edge_list_flat = edge_list.flatten()\n","\n","# initialize label encoder and transform\n","label_encoder = LabelEncoder()\n","num_instances = label_encoder.fit_transform(edge_list_flat)\n","num_instances = num_instances.reshape(edge_list.shape)# reshape to og shape"],"metadata":{"id":"Nul57wN7bxKF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_instances = torch.tensor( num_instances.astype('int64') )"],"metadata":{"id":"jp4INatydRM0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GCN(hidden_channels=4)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","losses,eps_list = [], []\n","\n","def train():\n","  model.train()\n","  optimizer.zero_grad() # clear gradients\n","  out = model(X, num_instances) # perform a single forward pass\n","  # print(f\"Output og shape: {out.shape}\")\n","  out = F.softmax(out,dim=1) # pass through softmax func\n","  # print(f\"Output after-softmax shape: {out.shape}\")\n","  loss = criterion(out, ytrain_en.float()) # compute the loss solely based on train nodes\n","  losses.append(loss.item())\n","  eps_list.append(epoch)\n","  loss.backward() # derive gradients\n","  optimizer.step() # update params\n","  return loss\n","\n","def dev():\n","  model.eval()\n","  out = model(flat_emb_de, edge_de)\n","  out = F.softmax(out,dim=1) # use the class with highest prob\n","  dev_loss = criterion(out, ydev_en.float()) # derive ratio of correct predictions\n","  return dev_loss\n","\n","for epoch in range(1, 10001):\n","  loss = train()\n","  # print(f\"Epoch: {epoch:03d}, loss: {loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":375},"id":"_sFbO4qiZ5-g","executionInfo":{"status":"error","timestamp":1715327187138,"user_tz":-180,"elapsed":398,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"d4d63574-0771-46cc-a3b9-03a11998dfe1"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"index 22411 is out of bounds for dimension 0 with size 1812","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-bd122db3486f>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0;31m# print(f\"Epoch: {epoch:03d}, loss: {loss:.4f}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-45-bd122db3486f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clear gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_instances\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# perform a single forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0;31m# print(f\"Output og shape: {out.shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# pass through softmax func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-ee6b531ee046>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[1;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mflow\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'source_to_target'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mdeg_inv_sqrt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeg_inv_sqrt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: index 22411 is out of bounds for dimension 0 with size 1812"]}]},{"cell_type":"code","source":["dev_loss = dev()\n","print(f'Dev CE-Loss: {dev_loss:.4f}')"],"metadata":{"id":"y5y-7B1uZ6CT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.scatter(eps_list, losses)"],"metadata":{"id":"cR1UJxbSaEjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!pip install torchviz\n","!sudo apt-get install graphviz"],"metadata":{"id":"wF3oLJPfaND5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchviz import make_dot\n","from torchsummary import summary\n","\n","y =  model(flat_emb_tr, edge_tr)\n","make_dot(y, params=dict(model.named_parameters()))"],"metadata":{"id":"jqDPm7hIaOFy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ENSEMBLES"],"metadata":{"id":"X1J94PR_gqX-"}},{"cell_type":"code","source":["# -- combine probabilities of all the models we want\n","probs_train = np.stack([ytr_b_xgb,ytr_xgb], axis=2)\n","\n","avg_probs_tr = np.mean(probs_train, axis=2) # average probability for each class all clfs\n","avg_probs_tr.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTt5ZI3LgtbU","executionInfo":{"status":"ok","timestamp":1715244704050,"user_tz":-180,"elapsed":267,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"2737b28d-2796-4ff6-da0f-b460cd3e9794"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1812, 9)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["ensemble_cross_en = multiclass_cross_entropy(ytrain_en, avg_probs_tr)\n","ensemble_cross_en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9IQEi7A5g8OK","executionInfo":{"status":"ok","timestamp":1715244704325,"user_tz":-180,"elapsed":1,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"548be909-1a2b-4f0c-9f64-34f873c0770f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.15567404"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["#### ENSEMBLES predict on TEST"],"metadata":{"id":"7BSPDLSYhGnS"}},{"cell_type":"code","source":["ytest_xgb = Xbg.predict_proba(w2v_test)\n","ytest_b_xgb = Xbg.predict_proba(w2v_test)\n","\n","\n","probs_test = np.stack([ytest_b_xgbytest_xgb, e], axis=2)\n","\n","avg_probs_test = np.mean(probs_test, axis=2) # average probability for each class all clfs\n","avg_probs_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8CC3XlT6hKTP","executionInfo":{"status":"ok","timestamp":1715244273183,"user_tz":-180,"elapsed":2,"user":{"displayName":"Dimitris Stathopoulos","userId":"13979344250441303776"}},"outputId":"8c8b47a6-1ce1-4f0b-8043-dab91815a39d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(605, 9)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# Write predictions to a file\n","with open('deepwalk_xgb.csv', 'w') as csvfile:\n","    writer = csv.writer(csvfile, delimiter=',')\n","    lst = list()\n","    for i in range(9):\n","        lst.append('class_'+str(i))\n","    lst.insert(0, \"domain_name\")\n","    writer.writerow(lst)\n","    for i,test_domain in enumerate(test_domains):\n","        lst = ytest_b_xgb[i,:].tolist()\n","        lst.insert(0, test_domain)\n","        writer.writerow(lst)"],"metadata":{"id":"owd6PPHnhSKo"},"execution_count":null,"outputs":[]}]}